{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWD81FyPPHRA",
        "colab_type": "text"
      },
      "source": [
        "# Location Aware Generative Advesarial Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux9gUtZsPLTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZC5doIqXNoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source: https://discuss.pytorch.org/t/locally-connected-layers/26979\n",
        "\n",
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "class LocallyConnected2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, output_size, kernel_size, stride, bias=False):\n",
        "        super(LocallyConnected2d, self).__init__()\n",
        "        output_size = _pair(output_size)\n",
        "        self.weight = nn.Parameter(\n",
        "            torch.randn(1, out_channels, in_channels, output_size[0], output_size[1], kernel_size**2)\n",
        "        )\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(\n",
        "                torch.randn(1, out_channels, output_size[0], output_size[1])\n",
        "            )\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.kernel_size = _pair(kernel_size)\n",
        "        self.stride = _pair(stride)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        _, c, h, w = x.size()\n",
        "        kh, kw = self.kernel_size\n",
        "        dh, dw = self.stride\n",
        "        x = x.unfold(2, kh, dh).unfold(3, kw, dw)\n",
        "        x = x.contiguous().view(*x.size()[:-2], -1)\n",
        "        # Sum in in_channel and kernel_size dims\n",
        "        out = (x.unsqueeze(1) * self.weight).sum([2, -1])\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XzvfWXPwSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "                        # Block I\n",
        "                        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5),\n",
        "                        nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
        "                        nn.Dropout(p=0.2, inplace=True),\n",
        "\n",
        "                        # Block II\n",
        "                        nn.ZeroPad2d(padding=2),\n",
        "                        LocallyConnected2d(in_channels=32, out_channels=8, kernel_size=5)\n",
        "                        nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
        "                        nn.BatchNorm2d(num_features=8, momentum=0.99, eps=1e-3),\n",
        "                        nn.Dropout(p=0.2, inplace=True),\n",
        "\n",
        "                        # Block III\n",
        "\n",
        "                     )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}