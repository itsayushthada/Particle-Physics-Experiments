{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWD81FyPPHRA"
   },
   "source": [
    "# Location Aware Generative Advesarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ux9gUtZsPLTW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torchgan.layers import MinibatchDiscrimination1d\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1D4IvbKhrhr"
   },
   "outputs": [],
   "source": [
    "import nn_local as nn_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JSzd0sxLvFDz"
   },
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74XzvfWXPwSi"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Base Deep Neural Network\n",
    "        self.common = nn.Sequential(\n",
    "                    # Block I\n",
    "                    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2),\n",
    "                    nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "                    nn.Dropout(p=0.2, inplace=True),\n",
    "\n",
    "                    # Block II\n",
    "                    nn.ZeroPad2d(padding=2),\n",
    "                    nn_.Conv2dLocal(in_height=29, in_width=29, in_channels=32, out_channels=8, kernel_size=5, stride=2),\n",
    "                    nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=8, momentum=0.99, eps=1e-3),\n",
    "                    nn.Dropout(p=0.2, inplace=True),\n",
    "\n",
    "                    # Block III\n",
    "                    nn.ZeroPad2d(padding=2),\n",
    "                    nn_.Conv2dLocal(in_height=17, in_width=17, in_channels=8, out_channels=8, kernel_size=5, stride=1),\n",
    "                    nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=8, momentum=0.99, eps=1e-3),\n",
    "                    nn.Dropout(p=0.2, inplace=True),\n",
    "\n",
    "                    # Block IV\n",
    "                    nn.ZeroPad2d(padding=2),\n",
    "                    nn_.Conv2dLocal(in_height=17, in_width=17, in_channels=8, out_channels=8, kernel_size=5, stride=2),\n",
    "                    nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=8, momentum=0.99, eps=1e-3),\n",
    "                    nn.Dropout(p=0.2, inplace=True),\n",
    "\n",
    "                    # Block V\n",
    "                    nn.AvgPool2d(kernel_size=2),\n",
    "                    nn.Flatten(),\n",
    "\n",
    "                    # Block VI [MinBatchDiscrimination for Mode Collapse Detection]\n",
    "                    MinibatchDiscrimination1d(in_features=72, out_features=20)\n",
    "                  )\n",
    "        \n",
    "        # Auxillary Output\n",
    "        self.auxo = nn.Sequential(\n",
    "                    nn.Linear(in_features=92, out_features=1),\n",
    "                    nn.Sigmoid()\n",
    "                  )\n",
    "        \n",
    "        # Prime Output\n",
    "        self.prim = nn.Sequential(\n",
    "                    nn.Linear(in_features=92, out_features=1),\n",
    "                    nn.Sigmoid()\n",
    "                  )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.common(input)\n",
    "        output = torch.cat([self.prim(output), self.auxo(output)], axis=-1)\n",
    "        return output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyGo-DTRiyxo"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Base Upscaler Deep Neural Netowrk\n",
    "        self.model  = nn.Sequential(\n",
    "                      # DCGAN Style Project and Reshaping\n",
    "                      nn.Linear(in_features=latent_dim, out_features=6272),\n",
    "                      nn_.Reshape(-1, 128, 7, 7),\n",
    "       \n",
    "                      # Block I\n",
    "                      nn.Conv2d(in_channels=128, out_channels=64, kernel_size=5, padding=2),\n",
    "                      nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "                      nn.BatchNorm2d(num_features=64, momentum=0.99, eps=1e-3),\n",
    "                      nn.UpsamplingNearest2d(scale_factor=2),\n",
    "        \n",
    "                      # Block II\n",
    "                      nn.ZeroPad2d(padding=2),\n",
    "                      nn_.Conv2dLocal(in_height=18, in_width=18, in_channels=64, out_channels=6, kernel_size=5, stride=1),\n",
    "                      nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "                      nn.BatchNorm2d(num_features=6, momentum=0.99, eps=1e-3),\n",
    "                      nn.UpsamplingNearest2d(scale_factor=2),\n",
    "\n",
    "                      # Block III\n",
    "                      nn_.Conv2dLocal(in_height=28, in_width=28, in_channels=6, out_channels=6, kernel_size=3, stride=1),\n",
    "                      nn.LeakyReLU(negative_slope=0.3, inplace=True),\n",
    "\n",
    "                      # Block IV\n",
    "                      nn_.Conv2dLocal(in_height=26, in_width=26, in_channels=6, out_channels=1, kernel_size=2, stride=1),\n",
    "                      nn.ReLU(inplace=True)\n",
    "                  )\n",
    "        \n",
    "        # Latent Vector(Z) and Auxillary Input Label\n",
    "        self.aux = nn.Embedding(num_embeddings=2, embedding_dim=latent_dim) \n",
    "\n",
    "    def forward(self, z, label):\n",
    "        hadmard_product = torch.mul(self.aux(label), z)\n",
    "        return self.model(hadmard_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5JIzDU9OYcjQ"
   },
   "source": [
    "### HyperParameters & Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPYTkiE8Tgqb"
   },
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "batch_size = 64\n",
    "latent_size = 200\n",
    "nb_classes = 2\n",
    "\n",
    "adam_lr = 0.05\n",
    "adam_beta_1 = 0.999\n",
    "adam_beta_2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nw1sFvltgtn8"
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "sample_interval = 1e3\n",
    "sample_count = 25\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_e43_6BYqd0"
   },
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXJnY-niTg5v"
   },
   "outputs": [],
   "source": [
    "disc_network = Discriminator()\n",
    "genr_network = Generator(latent_size)\n",
    "\n",
    "if cuda:\n",
    "    disc_network.cuda()\n",
    "    genr_network.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qFXow0RZkg4"
   },
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6WHYCnBTg9x"
   },
   "outputs": [],
   "source": [
    "adv_loss = torch.nn.BCELoss()\n",
    "\n",
    "if cuda:\n",
    "    adv_loss.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdhOn5otbWVV"
   },
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsbnloR4ThD8"
   },
   "outputs": [],
   "source": [
    "optimizer_d = torch.optim.Adam(disc_network.parameters(), \n",
    "                               lr=adam_lr, \n",
    "                               betas=(adam_beta_1, adam_beta_2))\n",
    "\n",
    "optimizer_g = torch.optim.Adam(genr_network.parameters(), \n",
    "                               lr=adam_lr, \n",
    "                               betas=(adam_beta_1, adam_beta_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbWUGF5ncK_I"
   },
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4U4ZO38ThHd"
   },
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFGwoGu0cYlf"
   },
   "outputs": [],
   "source": [
    "#### Dataloader to be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTbLlo2Fcgom"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppod1wWocf9e"
   },
   "outputs": [],
   "source": [
    "for epoch in range(nb_epochs):\n",
    "    for i, imgs in dataloader:\n",
    "        # Adversarial ground truths\n",
    "        real = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # Training of Generator\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        # Sample Gaussian Noise and Uniformly Distributed Labels\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_size))))\n",
    "        labels = Variable(Tensor(np.random.randint(0, nb_classes, imgs.shape[0])))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = genr_network(z, labels)\n",
    "\n",
    "        # Generator Loss\n",
    "        g_loss = adv_loss(disc_network(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Training of Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # Discriminator Losses\n",
    "        auxlr_real_loss = adv_loss(disc_network(real_imgs), real)\n",
    "        auxlr_real_loss = adv_loss(disc_network(real_imgs), real)\n",
    "        auxlr_fake_loss = adv_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        prime_fake_loss = adv_loss(discriminator(gen_imgs.detach()), fake)\n",
    "\n",
    "        d_loss = 0.25*(auxlr_real_loss + auxlr_real_loss + auxlr_fake_loss + prime_fake_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"[Epoch {}/{}] [Batch {}/{}] [D loss: {:0.8f}] [G loss: {:0.8f}]\".\\\n",
    "                  format(epoch, nb_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "\n",
    "        batches_done = (epoch * len(dataloader) + i)\n",
    "        if  batches_done % sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:sample_count], \n",
    "                       \"images/%d.png\".format(batches_done), \n",
    "                       nrow=5, \n",
    "                       normalize=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LAGAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
