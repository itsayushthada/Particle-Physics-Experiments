{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Identification Task Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will train a classifier to identify type of a particle. There are six particle types: electron, proton, muon, kaon, pion and ghost. Ghost is a particle with other type than the first five or a detector noise. \n",
    "\n",
    "Different particle types remain different responses in the detector systems or subdetectors. Thre are five systems: tracking system, ring imaging Cherenkov detector (RICH), electromagnetic and hadron calorimeters, and muon system.\n",
    "\n",
    "![pid](Images/pid.jpg)\n",
    "\n",
    "My aim is to identify a particle type using the responses in the detector systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('Data/training.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Information\n",
    "\n",
    "Following quantities stands for\n",
    "+ **Spd** : Scintillating Pad Detector\n",
    "+ **Prs** : Preshower\n",
    "+ **Ecal** : Electromagnetic Calorimeter\n",
    "+ **Hcal** : Hadronic Calorimeter\n",
    "+ **Brem** : Denotes traces of the Particles that were deflected by Detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Descripions are as follows:\n",
    "\n",
    "- ***ID*** : id value for tracks (presents only in the test file for the submitting purposes)\n",
    "- ***Label*** : string valued observable denoting particle types. Can take values \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" and \"Ghost\". This column is absent in the test file.\n",
    "- ***FlagSpd*** : flag (0 or 1), if reconstructed track passes through Spd\n",
    "- ***FlagPrs*** : flag (0 or 1), if reconstructed track passes through Prs\n",
    "- ***FlagBrem*** : flag (0 or 1), if reconstructed track passes through Brem\n",
    "- ***FlagEcal*** : flag (0 or 1), if reconstructed track passes through Ecal\n",
    "- ***FlagHcal*** : flag (0 or 1), if reconstructed track passes through Hcal\n",
    "- ***FlagRICH1*** : flag (0 or 1), if reconstructed track passes through the first RICH detector\n",
    "- ***FlagRICH2*** : flag (0 or 1), if reconstructed track passes through the second RICH detector\n",
    "- ***FlagMuon*** : flag (0 or 1), if reconstructed track passes through muon stations (Muon)\n",
    "- ***SpdE*** : energy deposit associated to the track in the Spd\n",
    "- ***PrsE*** : energy deposit associated to the track in the Prs\n",
    "- ***EcalE*** : energy deposit associated to the track in the Hcal\n",
    "- ***HcalE*** : energy deposit associated to the track in the Hcal\n",
    "- ***PrsDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Prs\n",
    "- ***BremDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Brem\n",
    "- ***TrackP*** : particle momentum\n",
    "- ***TrackPt*** : particle transverse momentum\n",
    "- ***TrackNDoFSubdetector1*** : number of degrees of freedom for track fit using hits in the tracking sub-detector1\n",
    "- ***TrackQualitySubdetector1*** : chi2 quality of the track fit using hits in the tracking sub-detector1\n",
    "- ***TrackNDoFSubdetector2*** : number of degrees of freedom for track fit using hits in the tracking sub-detector2\n",
    "- ***TrackQualitySubdetector2*** : chi2 quality of the track fit using hits in the  tracking sub-detector2\n",
    "- ***TrackNDoF*** : number of degrees of freedom for track fit using hits in all tracking sub-detectors\n",
    "- ***TrackQualityPerNDoF*** : chi2 quality of the track fit per degree of freedom\n",
    "- ***TrackDistanceToZ*** : distance between track and z-axis (beam axis)\n",
    "- ***Calo2dFitQuality*** : quality of the 2d fit of the clusters in the calorimeter \n",
    "- ***Calo3dFitQuality*** : quality of the 3d fit in the calorimeter with assumption that particle was electron\n",
    "- ***EcalDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Ecal\n",
    "- ***EcalDLLbeMuon*** : delta log-likelihood for a particle candidate to be muon using information from Ecal\n",
    "- ***EcalShowerLongitudinalParameter*** : longitudinal parameter of Ecal shower\n",
    "- ***HcalDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Hcal\n",
    "- ***HcalDLLbeMuon*** : delta log-likelihood for a particle candidate to be using information from Hcal\n",
    "- ***RICHpFlagElectron*** : flag (0 or 1) if momentum is greater than threshold for electrons to produce Cherenkov light\n",
    "- ***RICHpFlagProton*** : flag (0 or 1) if momentum is greater than threshold for protons to produce Cherenkov light\n",
    "- ***RICHpFlagPion*** : flag (0 or 1) if momentum is greater than threshold for pions to produce Cherenkov light\n",
    "- ***RICHpFlagKaon*** : flag (0 or 1) if momentum is greater than threshold for kaons to produce Cherenkov light\n",
    "- ***RICHpFlagMuon*** : flag (0 or 1) if momentum is greater than threshold for muons to produce Cherenkov light\n",
    "- ***RICH_DLLbeBCK *** : delta log-likelihood for a particle candidate to be background using information from RICH\n",
    "- ***RICH_DLLbeKaon*** : delta log-likelihood for a particle candidate to be kaon using information from RICH\n",
    "- ***RICH_DLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from RICH\n",
    "- ***RICH_DLLbeMuon*** : delta log-likelihood for a particle candidate to be muon using information from RICH\n",
    "- ***RICH_DLLbeProton*** : delta log-likelihood for a particle candidate to be proton using information from RICH\n",
    "- ***MuonFlag*** : muon flag (is this track muon) which is determined from muon stations\n",
    "- ***MuonLooseFlag*** : muon flag (is this track muon) which is determined from muon stations using looser criteria\n",
    "- ***MuonLLbeBCK*** : log-likelihood for a particle candidate to be not muon using information from muon stations\n",
    "- ***MuonLLbeMuon*** : log-likelihood for a particle candidate to be muon using information from muon stations\n",
    "- ***DLLelectron*** : delta log-likelihood for a particle candidate to be electron using information from all subdetectors\n",
    "- ***DLLmuon*** : delta log-likelihood for a particle candidate to be muon using information from all subdetectors\n",
    "- ***DLLkaon*** : delta log-likelihood for a particle candidate to be kaon using information from all subdetectors\n",
    "- ***DLLproton*** : delta log-likelihood for a particle candidate to be proton using information from all subdetectors\n",
    "- ***GhostProbability*** : probability for a particle candidate to be ghost track. This variable is an output of classification model used in the tracking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta log-likelihood in the features descriptions means the difference between log-likelihood for the mass hypothesis that a given track is left by some particle (for example, electron) and log-likelihood for the mass hypothesis that a given track is left by a pion (so, DLLpion = 0 and thus we don't have these columns). This is done since most tracks (~80%) are left by pions and in practice we actually need to discriminate other particles from pions. In other words, the null hypothesis is that particle is a pion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Labels\n",
    "\n",
    "set(data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Labels into Numerical Factor\n",
    "\n",
    "data['Class'] = utils.get_class_ids(data.Label.values)\n",
    "set(data.Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Features\n",
    "\n",
    "The following set of features describe particle responses in the detector systems:\n",
    "\n",
    "![features](Images/features.jpeg)\n",
    "\n",
    "Also there are several combined features. The full list is following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(data.columns) - {'Label', 'Class'})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding New Features\n",
    "\n",
    "def add_features(data):\n",
    "    trans = MinMaxScaler()\n",
    "    data[\"TRACK\"] = (1e-20 + trans.fit_transform(data[[x for x in data.columns if \"track\" in x.lower()]])).prod(axis=1)\n",
    "    data[\"RICH\"] = (1e-20 + trans.fit_transform(data[[x for x in data.columns if \"rich\" in x.lower()]])).prod(axis=1)\n",
    "    data[\"ELECTRO\"] = (1e-20 + trans.fit_transform(data[[x for x in data.columns if \"ecal\" in x.lower()]])).prod(axis=1)\n",
    "    data[\"HADRON\"] = (1e-20 + trans.fit_transform(data[[x for x in data.columns if \"hcal\" in x.lower()]])).prod(axis=1)\n",
    "    data[\"MUON\"] = (1e-20 + trans.fit_transform(data[[x for x in data.columns if \"muon\" in x.lower() and \n",
    "                                                                                 \"rich\" not in x.lower() and \n",
    "                                                                                 \"ecal\" not in x.lower()]])).prod(axis=1)\n",
    "    \n",
    "    for a,b in combinations([\"TRACK\", \"RICH\", \"ELECTRO\", \"HADRON\", \"MUON\"], 2):\n",
    "        data[\"{}__X__{}\".format(a.lower(), b.lower())] = data[a] * data[b]\n",
    "\n",
    "    mask_df = 1 * (data[ data.columns[data.min() == -999] ] != -999)\n",
    "    mask_df.columns = [x+\"_mask\" for x in mask_df.columns]\n",
    "\n",
    "    square_df = 0\n",
    "    if \"Label\" in data.columns:\n",
    "        square_df = data.drop(\"Label\", axis=1) **2\n",
    "    else:\n",
    "        square_df = data**2\n",
    "    square_df.columns = [x+\"_sq\" for x in square_df.columns]\n",
    "\n",
    "    data = pandas.concat([data, mask_df, square_df], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the Features list\n",
    "\n",
    "features = list(set(data.columns) - {'Label', 'Class'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = train_test_split(data, random_state=11, train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Input\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ReLU, Softmax\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Embedding, multiply\n",
    "import keras.initializers as inits\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=input_dim, kernel_initializer=inits.glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(100, input_dim=input_dim, kernel_initializer=inits.glorot_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Dense(6, kernel_initializer=inits.glorot_normal()))\n",
    "    model.add(Softmax())\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_obj = StandardScaler()\n",
    "sd_obj.fit(training_data[features].values)\n",
    "\n",
    "X_train = sd_obj.transform(training_data[features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = classifier(X.shape[1])\n",
    "\n",
    "nn.fit(X_train, \n",
    "      np_utils.to_categorical(training_data.Class.values), \n",
    "      verbose=1, \n",
    "      epochs=10, \n",
    "      batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss on the Validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = sd_obj.transform(validation_data[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for each Track [Aim: Hit lower than or equal to 0.525]\n",
    "\n",
    "proba_nn = nn.predict_proba(X_valid)\n",
    "log_loss(validation_data.Class.values, proba_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Metrics\n",
    "\n",
    "Plotting ROC curves and signal efficiency dependece from particle mometum and transverse momentum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = proba_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_roc_curves(proba, validation_data.Class.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_signal_efficiency_on_p(proba, validation_data.Class.values, validation_data.TrackP.values, 60, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_signal_efficiency_on_pt(proba, validation_data.Class.values, validation_data.TrackPt.values, 60, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decorrelation Using Adversarial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
