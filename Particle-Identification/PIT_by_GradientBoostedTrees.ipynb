{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Identification Task Using Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will train a classifier to identify type of a particle. There are six particle types: electron, proton, muon, kaon, pion and ghost. Ghost is a particle with other type than the first five or a detector noise. \n",
    "\n",
    "Different particle types remain different responses in the detector systems or subdetectors. Thre are five systems: tracking system, ring imaging Cherenkov detector (RICH), electromagnetic and hadron calorimeters, and muon system.\n",
    "\n",
    "![pid](Images/pid.jpg)\n",
    "\n",
    "My aim is to identify a particle type using the responses in the detector systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('Data/training.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Information\n",
    "\n",
    "Following quantities stands for\n",
    "+ **Spd** : Scintillating Pad Detector\n",
    "+ **Prs** : Preshower\n",
    "+ **Ecal** : Electromagnetic Calorimeter\n",
    "+ **Hcal** : Hadronic Calorimeter\n",
    "+ **Brem** : Denotes traces of the Particles that were deflected by Detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Descripions are as follows:\n",
    "\n",
    "- ***ID*** : id value for tracks (presents only in the test file for the submitting purposes)\n",
    "- ***Label*** : string valued observable denoting particle types. Can take values \"Electron\", \"Muon\", \"Kaon\", \"Proton\", \"Pion\" and \"Ghost\". This column is absent in the test file.\n",
    "- ***FlagSpd*** : flag (0 or 1), if reconstructed track passes through Spd\n",
    "- ***FlagPrs*** : flag (0 or 1), if reconstructed track passes through Prs\n",
    "- ***FlagBrem*** : flag (0 or 1), if reconstructed track passes through Brem\n",
    "- ***FlagEcal*** : flag (0 or 1), if reconstructed track passes through Ecal\n",
    "- ***FlagHcal*** : flag (0 or 1), if reconstructed track passes through Hcal\n",
    "- ***FlagRICH1*** : flag (0 or 1), if reconstructed track passes through the first RICH detector\n",
    "- ***FlagRICH2*** : flag (0 or 1), if reconstructed track passes through the second RICH detector\n",
    "- ***FlagMuon*** : flag (0 or 1), if reconstructed track passes through muon stations (Muon)\n",
    "- ***SpdE*** : energy deposit associated to the track in the Spd\n",
    "- ***PrsE*** : energy deposit associated to the track in the Prs\n",
    "- ***EcalE*** : energy deposit associated to the track in the Hcal\n",
    "- ***HcalE*** : energy deposit associated to the track in the Hcal\n",
    "- ***PrsDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Prs\n",
    "- ***BremDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Brem\n",
    "- ***TrackP*** : particle momentum\n",
    "- ***TrackPt*** : particle transverse momentum\n",
    "- ***TrackNDoFSubdetector1*** : number of degrees of freedom for track fit using hits in the tracking sub-detector1\n",
    "- ***TrackQualitySubdetector1*** : chi2 quality of the track fit using hits in the tracking sub-detector1\n",
    "- ***TrackNDoFSubdetector2*** : number of degrees of freedom for track fit using hits in the tracking sub-detector2\n",
    "- ***TrackQualitySubdetector2*** : chi2 quality of the track fit using hits in the  tracking sub-detector2\n",
    "- ***TrackNDoF*** : number of degrees of freedom for track fit using hits in all tracking sub-detectors\n",
    "- ***TrackQualityPerNDoF*** : chi2 quality of the track fit per degree of freedom\n",
    "- ***TrackDistanceToZ*** : distance between track and z-axis (beam axis)\n",
    "- ***Calo2dFitQuality*** : quality of the 2d fit of the clusters in the calorimeter \n",
    "- ***Calo3dFitQuality*** : quality of the 3d fit in the calorimeter with assumption that particle was electron\n",
    "- ***EcalDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Ecal\n",
    "- ***EcalDLLbeMuon*** : delta log-likelihood for a particle candidate to be muon using information from Ecal\n",
    "- ***EcalShowerLongitudinalParameter*** : longitudinal parameter of Ecal shower\n",
    "- ***HcalDLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from Hcal\n",
    "- ***HcalDLLbeMuon*** : delta log-likelihood for a particle candidate to be using information from Hcal\n",
    "- ***RICHpFlagElectron*** : flag (0 or 1) if momentum is greater than threshold for electrons to produce Cherenkov light\n",
    "- ***RICHpFlagProton*** : flag (0 or 1) if momentum is greater than threshold for protons to produce Cherenkov light\n",
    "- ***RICHpFlagPion*** : flag (0 or 1) if momentum is greater than threshold for pions to produce Cherenkov light\n",
    "- ***RICHpFlagKaon*** : flag (0 or 1) if momentum is greater than threshold for kaons to produce Cherenkov light\n",
    "- ***RICHpFlagMuon*** : flag (0 or 1) if momentum is greater than threshold for muons to produce Cherenkov light\n",
    "- ***RICH_DLLbeBCK *** : delta log-likelihood for a particle candidate to be background using information from RICH\n",
    "- ***RICH_DLLbeKaon*** : delta log-likelihood for a particle candidate to be kaon using information from RICH\n",
    "- ***RICH_DLLbeElectron*** : delta log-likelihood for a particle candidate to be electron using information from RICH\n",
    "- ***RICH_DLLbeMuon*** : delta log-likelihood for a particle candidate to be muon using information from RICH\n",
    "- ***RICH_DLLbeProton*** : delta log-likelihood for a particle candidate to be proton using information from RICH\n",
    "- ***MuonFlag*** : muon flag (is this track muon) which is determined from muon stations\n",
    "- ***MuonLooseFlag*** : muon flag (is this track muon) which is determined from muon stations using looser criteria\n",
    "- ***MuonLLbeBCK*** : log-likelihood for a particle candidate to be not muon using information from muon stations\n",
    "- ***MuonLLbeMuon*** : log-likelihood for a particle candidate to be muon using information from muon stations\n",
    "- ***DLLelectron*** : delta log-likelihood for a particle candidate to be electron using information from all subdetectors\n",
    "- ***DLLmuon*** : delta log-likelihood for a particle candidate to be muon using information from all subdetectors\n",
    "- ***DLLkaon*** : delta log-likelihood for a particle candidate to be kaon using information from all subdetectors\n",
    "- ***DLLproton*** : delta log-likelihood for a particle candidate to be proton using information from all subdetectors\n",
    "- ***GhostProbability*** : probability for a particle candidate to be ghost track. This variable is an output of classification model used in the tracking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta log-likelihood in the features descriptions means the difference between log-likelihood for the mass hypothesis that a given track is left by some particle (for example, electron) and log-likelihood for the mass hypothesis that a given track is left by a pion (so, DLLpion = 0 and thus we don't have these columns). This is done since most tracks (~80%) are left by pions and in practice we actually need to discriminate other particles from pions. In other words, the null hypothesis is that particle is a pion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Labels\n",
    "\n",
    "set(data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Labels into Numerical Factor\n",
    "\n",
    "data['Class'] = utils.get_class_ids(data.Label.values)\n",
    "set(data.Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Features\n",
    "\n",
    "The following set of features describe particle responses in the detector systems:\n",
    "\n",
    "![features](Images/features.jpeg)\n",
    "\n",
    "Also there are several combined features. The full list is following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(data.columns) - {'Label', 'Class'})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = train_test_split(data, random_state=11, train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "gb = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                n_estimators=50, \n",
    "                                subsample=0.3, \n",
    "                                random_state=13,\n",
    "                                min_samples_leaf=100, \n",
    "                                max_depth=3)\n",
    "\n",
    "gb.fit(training_data[features].values, training_data.Class.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for each track\n",
    "\n",
    "proba_gb = gb.predict_proba(validation_data[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error in the prediction {Log Loss}\n",
    "\n",
    "log_loss(validation_data.Class.values, proba_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from skopt import Optimizer\n",
    "from skopt.utils import create_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [(0.1, 0.3), # Learning Rate\n",
    "                (50, 1000), # Estimators\n",
    "                (0.2, 0.5), # SubSample\n",
    "                (80, 140) # Minimum Leaf Node\n",
    "                (2, 5) # Max Depth\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(params):\n",
    "    learning_rate, n_estimators, subsample, min_samples_leaf, max_depth = params\n",
    "\n",
    "    gb = GradientBoostingClassifier(learning_rate = learning_rate, \n",
    "                                n_estimators = n_estimators, \n",
    "                                subsample = subsample, \n",
    "                                random_state = 13,\n",
    "                                min_samples_leaf = min_samples_leaf, \n",
    "                                max_depth = max_depth)\n",
    "\n",
    "    gb.fit(training_data[features].values, training_data.Class.values)\n",
    "    proba_gb = gb.predict_proba(validation_data[features].values)\n",
    "    return gb, log_loss(validation_data.Class.values, proba_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(10)):\n",
    "    next_x = opt.ask()\n",
    "    _, f_val = model_loss(next_x)\n",
    "    opt.tell(next_x, f_val)\n",
    "    \n",
    "res = create_result(Xi = opt.Xi, \n",
    "                    yi = opt.yi, \n",
    "                    space = opt.space,\n",
    "                    rng = opt.rng, \n",
    "                    models = opt.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence Traces\n",
    "\n",
    "skopt.plots.plot_convergence(res)\n",
    "print (list(zip([\"learning_rate\", \"n_estimators\", \"subsample\", \"min_samples_leaf\", \"max_depth\"], res.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative regret traces\n",
    "\n",
    "skopt.plots.plot_regret(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise dependence plot of the objective function\n",
    "\n",
    "skopt.plots.plot_objective(res, dimensions=[\"learning_rate\", \"n_estimators\", \"subsample\", \"min_samples_leaf\", \"max_depth\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the order in which points where sampled.\n",
    "# The order in which samples were evaluated is encoded in each pointâ€™s color.\n",
    "\n",
    "skopt.plots.plot_evaluations(res, dimensions=[\"learning_rate\", \"n_estimators\", \"subsample\", \"min_samples_leaf\", \"max_depth\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb, loss =  model_loss(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Loss for Gradeint Boosted Trees is: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
